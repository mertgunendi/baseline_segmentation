# -*- coding: utf-8 -*-
"""baseline_segmentation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b6DkmODCEDQ2JWAMR9LsJ84IPriSrOe8

# 1. Getting Data
"""

!wget -O data.zip https://www.dropbox.com/scl/fi/k75ag58i704c7lgsdsvia/C2Seg_AB_splitted.zip?rlkey=jzxsa9ps06x64vfxt4e6rl0l5

import zipfile

data_path = "data"
with zipfile.ZipFile("data.zip", "r") as zip_ref:
    print("Unzipping data...")
    zip_ref.extractall(data_path)

"""## 1.1. Visualize Data"""

from osgeo import gdal

def get_image(folder_path, index):
  file_path_msi = folder_path + '/msi/'+str(index)+'.tiff'
  file_path_sar = folder_path + '/sar/'+str(index)+'.tiff'
  file_path_label = folder_path + '/label/'+str(index)+'.tiff'

  img_msi = gdal.Open(file_path_msi)
  array_msi = img_msi.ReadAsArray()

  img_sar = gdal.Open(file_path_sar)
  array_sar = img_sar.ReadAsArray()

  img_label = gdal.Open(file_path_label)
  array_label = img_label.ReadAsArray()

  return array_msi, array_sar, array_label

folder_path = "/content/data/train"
index = 0
msi, sar, label = get_image(folder_path, index)

msi.shape, sar.shape, label.shape

import numpy as np
from matplotlib.colors import ListedColormap

label_map = np.array([
      (0, 0, 0),          # 0 - Background (Black)
      (0, 0, 255),        # 1 - Surface water (Blue)
      (135, 206, 250),    # 2 - Street (Light Sky Blue)
      (255, 255, 0),      # 3 - Urban Fabric (Yellow)
      (128, 0, 0),        # 4 - Industrial, commercial and transport (Maroon)
      (139, 37, 0),       # 5 - Mine, dump, and construction sites (Reddish Brown)
      (0, 128, 0),        # 6 - Artificial, vegetated areas (Green)
      (255, 165, 0),      # 7 - Arable Land (Orange)
      (0, 255, 0),        # 8 - Permanent Crops (Lime Green)
      (154, 205, 50),     # 9 - Pastures (Yellow Green)
      (34, 139, 34),      # 10 - Forests (Forest Green)
      (139, 69, 19),      # 11 - Shrub (Saddle Brown)
      (245, 245, 220),    # 12 - Open spaces with no vegetation (Beige)
      (0, 255, 255),      # 13 - Inland wetlands (Cyan)
  ])

labels = [
    "Background", "Surface water", "Street", "Urban Fabric", "Industrial, commercial and transport",
    "Mine, dump, and construction sites", "Artificial, vegetated areas", "Arable Land",
    "Permanent Crops", "Pastures", "Forests", "Shrub", "Open spaces with no vegetation", "Inland wetlands"
]

cls_to_label = {i: label for i, label in enumerate(labels)}
label_to_cls = {label: i for i, label in enumerate(labels)}

cmap = ListedColormap(label_map / 255.0)
NUM_CLASSES = len(labels)
NUM_CLASSES

import matplotlib.pyplot as plt

def visualize_img(msi, sar, label):
  msi = msi.copy()
  msi = msi - msi.min()
  msi = msi / msi.max()

  plt.figure(figsize=(15, 15))

  plt.subplot(3, 2, 1)
  plt.title("RGB")
  plt.imshow(msi[0:3].transpose(1, 2, 0))
  plt.axis('off')

  plt.subplot(3, 2, 2)
  plt.title("NIR")
  plt.imshow(msi[3], cmap='gray')
  plt.axis("off")

  plt.subplot(3, 2, 3)
  plt.title("SAR VV")
  plt.imshow(sar[0], cmap='gray')
  plt.axis("off")

  plt.subplot(3, 2, 4)
  plt.title("SAR VH")
  plt.imshow(sar[1], cmap='gray')
  plt.axis("off")

  plt.subplot(3, 1, 3)
  plt.title("Label")
  plt.imshow(label, cmap=cmap, vmin=0, vmax=NUM_CLASSES-1)
  plt.axis("off")

  plt.subplots_adjust(wspace=0.01, hspace=0.09)

  plt.show()

visualize_img(msi, sar, label)

!pip install albumentations -q

import torch
from torch.utils.data import Dataset
import os

class SegmentaionDataset(Dataset):
  def __init__(self, folder_path, transform= None):
    self.folder_path = folder_path
    self.transform = transform
    self.data_count = len(os.listdir(folder_path + '/msi'))

  def __len__(self):
    return self.data_count

  def __getitem__(self, index):
    msi, sar, label = get_image(self.folder_path, index)
    img = np.vstack([msi, sar])
    if self.transform:
      result = self.transform(image=img.transpose(1, 2, 0), mask=label)
      img = result['image']
      label = result['mask']
    return img, label

import albumentations as A
from albumentations.pytorch import ToTensorV2
transform = A.Compose([
    ToTensorV2(),
])
train_dataset = SegmentaionDataset("/content/data/train", transform)
val_dataset = SegmentaionDataset("/content/data/val", transform)
test_dataset = SegmentaionDataset("/content/data/test", transform)
print(len(train_dataset), len(val_dataset), len(test_dataset))

img, label = train_dataset[19]
msi = img[:4].numpy()
sar = img[4:].numpy()

print(msi.shape, sar.shape, label.shape)
visualize_img(msi, sar, label)

device = 'cuda' if torch.cuda.is_available() else 'cpu'
device

# Commented out IPython magic to ensure Python compatibility.
# %pip install segmentation-models-pytorch -q

import segmentation_models_pytorch as smp

model = smp.UnetPlusPlus(
    encoder_name="timm-resnest14d",
    encoder_weights="imagenet",
    in_channels=6,
    classes=14,
).to(device)

# Commented out IPython magic to ensure Python compatibility.
# %pip install torchinfo -q

from torchinfo import summary

summary(model, input_size=(1, 6, 128, 128))

# Commented out IPython magic to ensure Python compatibility.
# %pip install torchmetrics -q

from torchmetrics.classification import MulticlassJaccardIndex

calculate_iou = MulticlassJaccardIndex(num_classes=NUM_CLASSES).to(device)

def train(model, train_loader, val_loader, loss_fn, optimizer, epochs):
  train_losses = []
  val_losses = []
  val_ious = []
  best_iou = 0.0
  best_epoch = 0

  for epoch in range(epochs):
    model.train()
    train_loss = 0.0
    for batch_idx, (images, labels) in enumerate(train_loader):
      images = images.to(device)
      labels = labels.to(device)

      optimizer.zero_grad()

      outputs = model(images)
      loss = loss_fn(outputs, labels.long())
      loss.backward()
      optimizer.step()

      train_loss += loss.item()

    train_loss /= len(train_loader)
    train_losses.append(train_loss)

    model.eval()
    val_loss = 0.0
    val_iou = 0.0
    with torch.no_grad():
      for images, labels in val_loader:
        images = images.to(device)
        labels = labels.to(device)

        outputs = model(images)
        loss = loss_fn(outputs, labels.long())
        iou = calculate_iou(outputs, labels)

        val_loss += loss.item()
        val_iou += iou.item()

      val_loss /= len(val_loader)
      val_losses.append(val_loss)

      val_iou /= len(val_loader)
      val_ious.append(val_iou)
    print(f"[Epoch {epoch+1}/{epochs}] | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val IoU: {100*val_iou:.2f}%")

    if val_iou > best_iou:
      best_iou = val_iou
      torch.save(model, "best_model.pth")
      best_epoch = epoch

  print(f"Best IoU: {100*best_iou:.2f}% saved at epoch {best_epoch+1}")
  return train_losses, val_losses, val_ious

train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)

loss_fn = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)

epochs = 200

x, y = next(iter(train_loader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

train_losses, val_losses, val_ious = train(model, train_loader, val_loader, loss_fn, optimizer, epochs)

import matplotlib.pyplot as plt

plt.figure(figsize=(15, 5))

plt.subplot(1, 2, 1)
plt.plot(train_losses, label='Train Loss')
plt.plot(val_losses, label='Val Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(val_ious, label='Val IoU')
plt.xlabel('Epoch')
plt.ylabel('IoU')
plt.yticks(np.arange(0, 1.1, 0.1))
plt.legend()

plt.show()

from torchmetrics.classification import MulticlassJaccardIndex
from torchmetrics.classification import MulticlassF1Score
from torchmetrics.classification import MulticlassPrecision
from torchmetrics.classification import MulticlassRecall

calculate_iou = MulticlassJaccardIndex(num_classes=NUM_CLASSES, average=None).to(device)
calculate_f1 = MulticlassF1Score(num_classes=NUM_CLASSES, average=None).to(device)
calculate_precision = MulticlassPrecision(num_classes=NUM_CLASSES, average=None).to(device)
calculate_recall = MulticlassRecall(num_classes=NUM_CLASSES, average=None).to(device)

import pandas as pd

best_model = torch.load("best_model.pth").to(device)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)

fscore_list = []
iou_list = []
precision_list = []
recall_list = []

best_model.eval()

for images, labels in test_loader:
  images = images.to(device)
  labels = labels.to(device)

  with torch.inference_mode():
    outputs = best_model(images)
    loss = loss_fn(outputs, labels.long())

  fscore_list.append(calculate_f1(outputs, labels))
  iou_list.append(calculate_iou(outputs, labels))
  precision_list.append(calculate_precision(outputs, labels))
  recall_list.append(calculate_recall(outputs, labels))

fscore =  torch.vstack(fscore_list).mean(dim=0)
iou =  torch.vstack(iou_list).mean(dim=0)
precision =  torch.vstack(precision_list).mean(dim=0)
recall =  torch.vstack(recall_list).mean(dim=0)

classwise_metrics_df = pd.DataFrame({
    "Class": [cls_to_label[i] for i in range(NUM_CLASSES)],
    "F1 Score": fscore.cpu().numpy(),
    "IoU": iou.cpu().numpy(),
    "Precision": precision.cpu().numpy(),
    "Recall": recall.cpu().numpy()
})

classwise_metrics_df

print(f"Mean F1 Score: {100*fscore.mean().item():.2f}%")
print(f"Mean IoU: {100*iou.mean().item():.2f}%")
print(f"Mean Precision: {100*precision.mean().item():.2f}%")
print(f"Mean Recall: {100*recall.mean().item():.2f}%")

import random

best_model.eval()
random_indices = random.sample(range(len(test_loader.dataset)), 10)

for index in random_indices:
  image, label = test_loader.dataset[index]
  image = image.to(device)
  label = label.to(device)

  with torch.inference_mode():
    output = best_model(image.unsqueeze(0))
    predicted_label = torch.argmax(output, dim=1).squeeze().cpu().numpy()
  plt.figure(figsize=(15, 15))

  image = image - image.min()
  image = image / image.max()
  plt.subplot(1, 3, 1)
  plt.title("RGB")
  plt.imshow(image[0:3].permute(1, 2, 0).cpu().numpy())
  plt.axis('off')

  plt.subplot(1, 3, 2)
  plt.title("True Label")
  plt.imshow(label.cpu().numpy(), cmap=cmap, vmin=0, vmax=NUM_CLASSES-1)
  plt.axis("off")

  plt.subplot(1, 3, 3)
  plt.title("Predicted Label")
  plt.imshow(predicted_label, cmap=cmap, vmin=0, vmax=NUM_CLASSES-1)
  plt.axis("off")

  plt.subplots_adjust(hspace=0.09)

  plt.show()

